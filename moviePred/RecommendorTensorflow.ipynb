{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from lightfm.datasets.movielens import fetch_movielens\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training['train'].toarray()[:100][0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeData(data):\n",
    "    trainModified=a=b=c=d=np.array([])\n",
    "    rows=cols=ratings=[]\n",
    "    for row_index in range(0,data.shape[0]):\n",
    "        for column_index in range(0,data.shape[1]) :\n",
    "            rows.append(row_index)\n",
    "            cols.append(column_index)\n",
    "            ratings.append(data[row_index,column_index])\n",
    "            print(str(ratings))\n",
    "        \n",
    "    a=np.array(rows)\n",
    "    b=np.array(cols)\n",
    "    c=np.array(ratings)\n",
    "    return a,b,c\n",
    "\n",
    "data_training=fetch_movielens()\n",
    "a,b,c=reshapeData(data_training['train'].toarray()[:100,])\n",
    "max_iter=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    lda = 10.0\n",
    "    rank = 5\n",
    "    num_users=train.shape[0]\n",
    "    num_items=train.shape[1]\n",
    "    global_mean = np.mean(train[:,2])\n",
    "    W, H, reg = create_factors_without_biases(num_users, num_items, rank, lda)\n",
    "   \n",
    "    tr, val, finalw, finalh = mf(train, test, W, H, reg, global_mean, max_iter, 1.0, True)\n",
    "    print(\"Final training RMSE %s\" % (tr))\n",
    "    print(\"Final validation RMSE %s\" % (val))\n",
    "\n",
    "    np.save(\"final_w\", finalw)\n",
    "    np.save(\"final_h\", finalh)\n",
    "\n",
    "def extract_rating_info(ratings):\n",
    "    rating_values = np.array(ratings[:,2], dtype=np.float32)\n",
    "    user_indices = ratings[:,0]\n",
    "    item_indices = ratings[:,1]\n",
    "    num_ratings = len(item_indices)\n",
    "    return rating_values, num_ratings, user_indices, item_indices\n",
    "\n",
    "def create_factors_without_biases(num_users, num_items, rank, lda):\n",
    "    # Initialize the matrix factors from random normals with mean 0. W will\n",
    "    # represent users and H will represent items.\n",
    "    W = tf.Variable(tf.truncated_normal([num_users, rank], stddev=0.02, mean=0), name=\"users\")\n",
    "    H = tf.Variable(tf.truncated_normal([rank, num_items], stddev=0.02, mean=0), name=\"items\")\n",
    "    regularizer = tf.multiply(tf.add(tf.reduce_sum(tf.square(W)), tf.reduce_sum(tf.square(H))), lda, name=\"regularize\")\n",
    "    return W, H, regularizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mf(ratings_train, ratings_val, W, H, regularizer, mean_rating, max_iter, lr = 0.01, decay_lr = False, log_summaries = True):\n",
    "    # Extract info from training and validation data\n",
    "    rating_values_tr, num_ratings_tr, user_indices_tr, item_indices_tr = extract_rating_info(ratings_train)\n",
    "    rating_values_val, num_ratings_val, user_indices_val, item_indices_val = extract_rating_info(ratings_val)\n",
    "\n",
    "    # Multiply the factors to get our result as a dense matrix\n",
    "    result = tf.matmul(W, H)\n",
    "\n",
    "    # Now we just want the values represented by the pairs of user and item\n",
    "    # indices for which we had known ratings.\n",
    "    result_values_tr = tf.gather(tf.reshape(result, [-1]), user_indices_tr * tf.shape(result)[1] + item_indices_tr, name=\"extract_training_ratings\")\n",
    "    result_values_val = tf.gather(tf.reshape(result, [-1]), user_indices_val * tf.shape(result)[1] + item_indices_val, name=\"extract_validation_ratings\")\n",
    "\n",
    "    # Calculate the difference between the predicted ratings and the actual\n",
    "    # ratings. The predicted ratings are the values obtained form the matrix\n",
    "    # multiplication with the mean rating added on.\n",
    "    diff_op = tf.subtract(tf.add(result_values_tr, mean_rating, name=\"add_mean\"), rating_values_tr, name=\"raw_training_error\")\n",
    "    diff_op_val = tf.subtract(tf.add(result_values_val, mean_rating, name=\"add_mean_val\"), rating_values_val, name=\"raw_validation_error\")\n",
    "\n",
    "    with tf.name_scope(\"training_cost\") as scope:\n",
    "        base_cost = tf.reduce_sum(tf.square(diff_op, name=\"squared_difference\"), name=\"sum_squared_error\")\n",
    "\n",
    "        cost = tf.div(tf.add(base_cost, regularizer), num_ratings_tr * 2, name=\"average_error\")\n",
    "\n",
    "    with tf.name_scope(\"validation_cost\") as scope:\n",
    "        cost_val = tf.div(tf.reduce_sum(tf.square(diff_op_val, name=\"squared_difference_val\"), name=\"sum_squared_error_val\"), num_ratings_val * 2, name=\"average_error\")\n",
    "\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        if decay_lr:\n",
    "            # Use an exponentially decaying learning rate.\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.96, staircase=True)\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "            # Passing global_step to minimize() will increment it at each step \n",
    "            # so that the learning rate will be decayed at the specified \n",
    "            # intervals.\n",
    "            train_step = optimizer.minimize(cost, global_step=global_step)\n",
    "        else:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "            train_step = optimizer.minimize(cost)\n",
    "\n",
    "    with tf.name_scope(\"training_rmse\") as scope:\n",
    "        rmse_tr = tf.sqrt(tf.reduce_sum(tf.square(diff_op)) / num_ratings_tr)\n",
    "\n",
    "    with tf.name_scope(\"validation_rmse\") as scope:\n",
    "      # Validation set rmse:\n",
    "      rmse_val = tf.sqrt(tf.reduce_sum(tf.square(diff_op_val)) / num_ratings_val)\n",
    "\n",
    "    # Create a TensorFlow session and initialize variables.\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    if log_summaries:\n",
    "        # Make sure summaries get written to the logs.\n",
    "        accuracy_val_summary = tf.summary.scalar(\"accuracy_val\", rmse_val)\n",
    "#         accuracy_tr_summary = tf.summary.scalar(\"accuracy_tr\", accuracy_tr)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(\"/summary\", sess.graph_def)\n",
    "    # Keep track of cost difference.\n",
    "    last_cost = 0\n",
    "    diff = 1\n",
    "    # Run the graph and see how we're doing on every 1000th iteration.\n",
    "    for i in range(max_iter*100):\n",
    "        if i > 0:\n",
    "            if diff < 0.000001:\n",
    "                print(\"Converged at iteration %s\" % (i))\n",
    "                break;\n",
    "            if log_summaries:\n",
    "                res = sess.run([rmse_tr, rmse_val, cost, summary_op])\n",
    "                summary_str = res[3]\n",
    "                writer.add_summary(summary_str, i)\n",
    "            else:\n",
    "                res = sess.run([rmse_tr, rmse_val, cost])\n",
    "            acc_tr = res[0]\n",
    "            acc_val = res[1]\n",
    "            cost_ev = res[2]\n",
    "            print(\"Training RMSE at step %s: %s\" % (i, acc_tr))\n",
    "            print(\"Validation RMSE at step %s: %s\" % (i, acc_val))\n",
    "            diff = abs(cost_ev - last_cost)\n",
    "            last_cost = cost_ev\n",
    "        else:\n",
    "            sess.run(train_step)\n",
    "            \n",
    "    finalTrain = rmse_tr.eval(session=sess)\n",
    "    finalVal = rmse_val.eval(session=sess)\n",
    "    finalW = W.eval(session=sess)\n",
    "    finalH = H.eval(session=sess)\n",
    "#     print(\"final W\",finalW)\n",
    "#     print(\"final H\",finalH)\n",
    "    sorted_movies=tf.matmul(finalW,finalH).eval(session=sess)[0].argsort()\n",
    "    print(finalW.shape)\n",
    "    sess.close()\n",
    "    return finalTrain, finalVal, finalW, finalH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\bkaushal\\aiva\\stockprediction\\tensordemo\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "Training RMSE at step 1: 470.281\n",
      "Validation RMSE at step 1: 470.303\n",
      "Training RMSE at step 2: 470.281\n",
      "Validation RMSE at step 2: 470.303\n",
      "Converged at iteration 3\n",
      "(1586126, 5)\n",
      "Final training RMSE 470.281\n",
      "Final validation RMSE 470.303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
